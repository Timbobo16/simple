{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  # deep learning library. Tensors are just multi-dimensional arrays\n",
    "\n",
    "mnist = tf.keras.datasets.mnist  # mnist is a dataset of 28x28 images of handwritten digits and their labels\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()  # unpacks images to x_train/x_test and labels to y_train/y_test\n",
    "\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1).reshape(x_train.shape[0], -1) # scales data between 0 and 1\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1).reshape(x_test.shape[0], -1)  # scales data between 0 and 1\n",
    "\n",
    "model = tf.keras.models.Sequential()  # a basic feed-forward model\n",
    "#model.add(tf.keras.layers.Flatten())  # takes our 28x28 and makes it 1x784\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n",
    "\n",
    "model.compile(optimizer='adam',  # Good default optimizer to start with\n",
    "              loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n",
    "              metrics=['accuracy'])  # what to track\n",
    "\n",
    "model.fit(x_train, y_train, epochs=3)  # train the model\n",
    "\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test)  # evaluate the out of sample data with model\n",
    "print(val_loss)  # model's loss (error)\n",
    "print(val_acc)  # model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import chess.svg\n",
    "import chess.pgn\n",
    "import chess.engine\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def board_fen_to_array(fenboard):\n",
    "    result = []\n",
    "    rows = fenboard.split('/')\n",
    "    for row in rows:\n",
    "        newrow = [x for x in row]\n",
    "        for c in row:\n",
    "            if c.isnumeric():\n",
    "                idx = row.index(c)\n",
    "                newrow.pop(idx)\n",
    "                for i in range(0, int(c)):\n",
    "                    newrow.insert(idx, '.')\n",
    "        result.append(newrow)\n",
    "    return result\n",
    "\n",
    "#print(fenboard_to_array(chess.STARTING_BOARD_FEN))\n",
    "\n",
    "def fen_to_array(fen):\n",
    "    fenlist = fen.split()\n",
    "    boardfen = fenlist.pop(0)\n",
    "    result = board_fen_to_array(boardfen)\n",
    "    result.extend(fenlist)\n",
    "    return result\n",
    "\n",
    "\n",
    "def convert_to_ascii(text):\n",
    "    return \"\".join(str(ord(char)) for char in text)\n",
    "\n",
    "\n",
    "def array_fen_to_int_array(fenarray):\n",
    "    for i in range(0,8):\n",
    "        for j in range(0,8):\n",
    "            fenarray[i][j]=ord(fenarray[i][j])\n",
    "    seven_zeros = [0,0,0,0,0,0,0]\n",
    "    fenarray[8] = [ord(fenarray[8])]\n",
    "    fenarray[8].extend(seven_zeros)\n",
    "    fenarray[9] = [int(convert_to_ascii(fenarray[9]))]\n",
    "    fenarray[9].extend(seven_zeros)\n",
    "    fenarray[10] = [int(convert_to_ascii(fenarray[10]))]\n",
    "    fenarray[10].extend(seven_zeros)\n",
    "    fenarray[11] = [int(fenarray[11])]\n",
    "    fenarray[11].extend(seven_zeros)\n",
    "    fenarray[12] = [int(fenarray[12])] \n",
    "    fenarray[12].extend(seven_zeros)\n",
    "    return np.array(fenarray)\n",
    "    \n",
    "\n",
    "def board_to_int_array(board):\n",
    "    return array_fen_to_int_array(fen_to_array(board.fen()))\n",
    "\n",
    "\n",
    "def uci_to_list(uci):\n",
    "    result = []\n",
    "    for c in uci:\n",
    "        result.append(ord(c))\n",
    "    if len(result) == 4:\n",
    "        result.insert(4, 32)\n",
    "    return result\n",
    "\n",
    "#print(uci_to_list('a7a8'))\n",
    "\n",
    "def list_to_bin_list(list):\n",
    "    result = np.zeros((640))\n",
    "    for i in range(len(list)):\n",
    "        offset = i*128\n",
    "        result[offset+list[i]] = 1\n",
    "    \n",
    "    return result\n",
    "\n",
    "#print(list_to_bin_list(uci_to_list('a7a8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "board = chess.Board('rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1')\n",
    "engine = chess.engine.SimpleEngine.popen_uci(\"stockfish_13_win_x64_bmi2/stockfish_13_win_x64_bmi2.exe\")\n",
    "\n",
    "for i in range(0, 10000):\n",
    "    if board.is_game_over():\n",
    "        board = chess.Board('rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1')\n",
    "    x_train.append(board_to_int_array(board))\n",
    "    move = engine.play(board, chess.engine.Limit(time=0.02))\n",
    "    board.push(move.move)\n",
    "    y_train.append(list_to_bin_list(uci_to_list(move.move.uci())))\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "#print(len(x_train))\n",
    "#print(x_train.shape)\n",
    "#print(x_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "(10000, 640)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(y_train))\n",
    "print(y_train.shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " logits and labels must have the same first dimension, got logits shape [32,640] and labels shape [20480]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-17-624ba479493b>:11) ]] [Op:__inference_train_function_22044]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-624ba479493b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m               \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# how will we calculate our \"error.\" Neural network aims to minimize loss.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m               metrics=['accuracy'])  # what to track\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\twash\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\twash\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\twash\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\twash\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\twash\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\twash\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\twash\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  logits and labels must have the same first dimension, got logits shape [32,640] and labels shape [20480]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-17-624ba479493b>:11) ]] [Op:__inference_train_function_22044]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model1 = tf.keras.models.Sequential() \n",
    "#model1.add(tf.keras.layers.Flatten())\n",
    "model1.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model1.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model1.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model1.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model1.add(tf.keras.layers.Dense(640, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n",
    "model1.compile(optimizer='adam',  # Good default optimizer to start with\n",
    "              loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n",
    "              metrics=['accuracy'])  # what to track\n",
    "model1.fit(x_train, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 30040517491584436.0000 - accuracy: 0.0125\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 6848682817745759232.0000 - accuracy: 0.0077\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 115435464756086964224.0000 - accuracy: 0.0073\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 10s 31ms/step - loss: nan - accuracy: 0.0103\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 9s 30ms/step - loss: nan - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2189cb90b48>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = tf.keras.models.Sequential() \n",
    "#model2.add(tf.keras.layers.Flatten())\n",
    "model2.add(tf.keras.layers.Dense(1024, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model2.add(tf.keras.layers.Dense(1024, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model2.add(tf.keras.layers.Dense(1024, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model2.add(tf.keras.layers.Dense(1024, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model2.add(tf.keras.layers.Dense(640, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n",
    "model2.compile(optimizer='adam',  # Good default optimizer to start with\n",
    "              loss='categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n",
    "              metrics=['accuracy'])  # what to track\n",
    "model2.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "313/313 [==============================] - 10s 30ms/step - loss: 98280.6992 - accuracy: 0.0000e+00ETA: 0s - loss: 99266.2278 - accuracy: 0.0000\n",
      "Epoch 2/2\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 1.8829 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2189e0f7ac8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = tf.keras.models.Sequential() \n",
    "#model3.add(tf.keras.layers.Flatten())\n",
    "model3.add(tf.keras.layers.Dense(1024, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model3.add(tf.keras.layers.Dense(1024, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model3.add(tf.keras.layers.Dense(1024, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model3.add(tf.keras.layers.Dense(1024, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model3.add(tf.keras.layers.Dense(640, activation=tf.nn.sigmoid))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n",
    "model3.compile(optimizer='adam',  # Good default optimizer to start with\n",
    "              loss='binary_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n",
    "              metrics=['accuracy'])  # what to track\n",
    "model3.fit(x_train, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "board = chess.Board('rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1')\n",
    "for i in range(0, 2000):\n",
    "    if board.is_game_over():\n",
    "        board = chess.Board('rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1')\n",
    "    x_test.append(board_to_int_array(board))\n",
    "    move = engine.play(board, chess.engine.Limit(time=0.02))\n",
    "    board.push(move.move)\n",
    "    y_test.append(list_to_bin_list(uci_to_list(move.move.uci())))\n",
    "    \n",
    "x_test = np.array(x_test)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544\n",
      "[6.2361360e-04 1.0899007e-03 1.1934042e-03 1.9925833e-04 5.7128072e-04\n",
      " 8.2707405e-04 1.8699467e-03 1.6540885e-03 1.0453165e-03 3.1545758e-04\n",
      " 1.6564131e-03 1.6972423e-03 5.5217743e-04 9.6514821e-04 1.7209947e-03\n",
      " 9.0670586e-04 1.4037192e-03 3.1262636e-04 7.0944428e-04 6.5416098e-04\n",
      " 6.2468648e-04 1.6290843e-03 7.8991055e-04 1.2883842e-03 2.7466416e-03\n",
      " 6.8143010e-04 4.6357512e-04 1.1092424e-03 6.7022443e-04 7.8225136e-04\n",
      " 5.9318542e-04 1.2417138e-03 5.8981776e-04 1.6804039e-03 6.4864755e-04\n",
      " 9.7027421e-04 1.3677776e-03 9.0536475e-04 1.5187860e-03 1.3562143e-03\n",
      " 4.6879053e-04 2.1052361e-04 2.3040175e-04 5.9953332e-04 2.1988750e-03\n",
      " 1.3985038e-03 3.1676888e-04 1.3710558e-03 1.6734898e-03 7.5349212e-04\n",
      " 1.8490553e-03 2.3003221e-03 6.1395764e-04 1.0685325e-03 5.0732493e-04\n",
      " 8.9776516e-04 1.0401607e-03 1.7737746e-03 2.7767718e-03 2.0810068e-03\n",
      " 1.2169480e-03 1.7057657e-03 1.6126335e-03 1.5296042e-03 3.3751130e-04\n",
      " 9.0810657e-04 2.6783347e-04 2.5538504e-03 2.2875369e-03 3.7202537e-03\n",
      " 7.5870752e-04 1.9577444e-03 6.7016482e-04 1.0646582e-03 1.1193454e-03\n",
      " 1.8973947e-03 2.0512938e-04 3.5309792e-04 1.6667843e-03 2.1523535e-03\n",
      " 1.4043450e-03 7.0551038e-04 6.7839026e-04 9.6082687e-04 3.2058358e-04\n",
      " 8.0984831e-04 1.1655390e-03 1.2061596e-03 1.8524528e-03 1.6275942e-03\n",
      " 6.7198277e-04 1.7637908e-03 1.4929771e-03 1.3461709e-03 1.0103285e-03\n",
      " 1.4621615e-03 7.1778893e-04 2.7910638e-01 3.1072697e-01 3.5296273e-01\n",
      " 3.7701330e-01 3.9001223e-01 3.2192016e-01 3.4723008e-01 2.9374215e-01\n",
      " 2.1901429e-03 8.2874298e-04 9.3635917e-04 3.2765269e-03 1.2854040e-03\n",
      " 2.2973418e-03 5.4237247e-04 1.4302433e-03 1.0927618e-03 1.1105835e-03\n",
      " 1.3910830e-03 6.7391992e-04 1.5394390e-03 1.5061796e-03 2.7904212e-03\n",
      " 2.1744072e-03 1.6628504e-03 1.6533434e-03 3.9973855e-04 2.3103952e-03\n",
      " 5.2165985e-04 1.6218424e-03 5.5640936e-04 6.1157346e-04 4.1013956e-04\n",
      " 6.5821409e-04 1.5425086e-03 1.2423694e-03 4.8455596e-04 8.2367659e-04\n",
      " 1.5553236e-03 1.9178689e-03 1.2412369e-03 7.1871281e-04 7.1558356e-04\n",
      " 1.7285049e-03 1.2348592e-03 7.7274442e-04 1.8978417e-03 5.6535006e-04\n",
      " 9.9346042e-04 8.1607699e-04 1.8327534e-03 1.2053549e-03 2.5200844e-03\n",
      " 6.1774254e-04 4.2936206e-04 1.7473102e-03 7.7646971e-04 2.6643872e-03\n",
      " 6.9206953e-04 7.8457594e-04 1.6488731e-03 2.5728345e-04 4.3600798e-04\n",
      " 1.5891194e-03 1.1146963e-03 5.7518482e-04 1.4452338e-03 1.0833740e-03\n",
      " 1.2015104e-03 8.0680847e-04 7.0744753e-04 2.5748312e-03 1.5024245e-03\n",
      " 9.9053979e-04 8.1422925e-04 4.1809678e-04 2.3038983e-03 1.3705194e-03\n",
      " 1.5068650e-03 3.9550662e-04 4.1358662e-01 4.4200006e-01 2.7336314e-01\n",
      " 3.0246860e-01 3.2568210e-01 3.4363818e-01 3.6681563e-01 3.4943742e-01\n",
      " 7.8839064e-04 2.3978353e-03 1.3590753e-03 6.2671304e-04 1.1620224e-03\n",
      " 1.0207593e-03 5.3650141e-04 9.1299415e-04 1.6748011e-03 1.8472075e-03\n",
      " 5.1286817e-04 3.1473041e-03 2.1702945e-03 1.3778210e-03 1.1066794e-03\n",
      " 7.3161721e-04 9.6023083e-04 1.0983348e-03 8.8927150e-04 2.5007427e-03\n",
      " 5.8236718e-04 1.0392964e-03 4.0182471e-04 4.5505166e-04 8.3726645e-04\n",
      " 8.7037683e-04 3.6814809e-04 3.0818582e-04 9.5412135e-04 8.9490414e-04\n",
      " 1.0319948e-03 5.0160289e-04 1.7918646e-03 1.3725758e-03 5.4547191e-04\n",
      " 4.5371056e-04 2.7131736e-03 4.5102835e-04 8.7627769e-04 1.5750527e-03\n",
      " 7.0726871e-04 2.3457408e-04 1.1933744e-03 1.5634596e-03 1.1301041e-03\n",
      " 5.9938431e-04 6.5609813e-04 4.8318505e-04 7.5805187e-04 1.6511381e-03\n",
      " 8.1259012e-04 4.1016936e-04 1.3452172e-03 3.6066771e-04 1.9272864e-03\n",
      " 9.1362000e-04 9.4738603e-04 4.4125319e-04 1.7230809e-03 6.5210462e-04\n",
      " 1.0267496e-03 6.7630410e-04 1.3690889e-03 2.8762817e-03 9.7015500e-04\n",
      " 9.6184015e-04 7.1513653e-04 2.0164251e-04 2.7517676e-03 6.8685412e-04\n",
      " 5.0359964e-04 1.6499460e-03 6.1526895e-04 7.3087215e-04 2.6488304e-04\n",
      " 1.2136102e-03 1.9397736e-03 1.6256869e-03 7.0247054e-04 7.6481700e-04\n",
      " 1.8094182e-03 1.5424788e-03 1.2339652e-03 1.2429059e-03 2.3185015e-03\n",
      " 2.3931265e-04 1.2246370e-03 8.4170699e-04 1.2113452e-03 1.0008812e-03\n",
      " 1.4744699e-03 2.4842322e-03 1.3659596e-03 1.3114810e-03 1.4276803e-03\n",
      " 1.5747547e-04 6.2698126e-04 2.9557943e-04 3.3317208e-03 2.2617877e-03\n",
      " 2.4656951e-03 2.7380884e-03 1.1429191e-03 7.4642897e-04 5.2082539e-04\n",
      " 7.9697371e-04 1.4167130e-03 1.2167394e-03 9.5170736e-04 4.2653084e-04\n",
      " 9.9781156e-04 3.9950013e-04 1.2162924e-03 4.7674775e-04 1.1792183e-03\n",
      " 2.2980571e-04 1.9431710e-03 6.0057640e-04 1.0827482e-03 7.1343780e-04\n",
      " 9.3004107e-04 4.4161081e-04 1.3315380e-03 7.8725815e-04 7.4946880e-04\n",
      " 6.9481134e-04 2.4770200e-03 1.4764965e-03 2.2655427e-03 5.6526065e-04\n",
      " 2.4898648e-03 9.6607208e-04 4.4375658e-04 1.9846261e-03 1.5155077e-03\n",
      " 3.1194985e-03 1.1570454e-03 8.9812279e-04 4.6238303e-04 7.8734756e-04\n",
      " 1.3068318e-03 9.5048547e-04 2.6611984e-03 8.8256598e-04 8.4346533e-04\n",
      " 1.5792847e-03 4.4149160e-04 9.0667605e-04 8.0525875e-04 3.0286014e-03\n",
      " 1.1114478e-03 6.7153573e-04 1.4947951e-03 9.7915530e-04 5.3787231e-04\n",
      " 7.5635314e-04 5.2821636e-04 3.2642484e-04 5.0553679e-04 6.6593289e-04\n",
      " 8.1309676e-04 1.0992587e-03 3.1819940e-04 8.8575482e-04 1.0281801e-03\n",
      " 9.0324879e-04 1.3122559e-03 2.6172400e-03 3.1892133e-01 2.3853973e-01\n",
      " 3.6985332e-01 3.8517955e-01 3.8595700e-01 3.4925938e-01 3.0224863e-01\n",
      " 2.6243949e-01 9.1853738e-04 1.2264252e-03 2.1524429e-03 1.4871359e-04\n",
      " 2.5573969e-03 8.9037418e-04 7.9986453e-04 2.1449029e-03 2.6773810e-03\n",
      " 1.1990666e-03 4.5412779e-04 1.3436079e-03 9.0301037e-04 1.2516677e-03\n",
      " 6.6268444e-04 5.9956312e-04 8.9564919e-04 5.5351853e-04 8.7016821e-04\n",
      " 1.6032457e-03 1.6435981e-03 1.8991530e-03 1.3199747e-03 1.2964308e-03\n",
      " 1.3279021e-03 5.9816241e-04 9.3105435e-04 2.7348399e-03 1.1644065e-03\n",
      " 4.1568279e-03 1.1200905e-03 4.9507618e-04 8.9916587e-04 2.0158589e-03\n",
      " 3.1572580e-04 7.3823333e-04 7.0667267e-04 1.3968647e-03 2.8416514e-04\n",
      " 1.9869804e-03 2.3219585e-03 2.0686090e-03 1.5427172e-03 7.7617168e-04\n",
      " 1.0634959e-03 4.4348836e-04 2.3048222e-03 1.7336011e-04 9.6774101e-04\n",
      " 5.9542060e-04 1.4940500e-03 1.0694265e-03 4.7069788e-04 1.0285974e-03\n",
      " 2.6300550e-03 2.2763312e-03 2.8600097e-03 3.4491122e-03 7.7551603e-04\n",
      " 1.0654628e-03 9.4485283e-04 8.5702538e-04 5.3671002e-04 7.7617168e-04\n",
      " 1.0982156e-03 1.8824041e-03 2.1342933e-03 8.0338120e-04 1.9462109e-03\n",
      " 1.4097393e-03 1.8594861e-03 1.1056960e-03 2.9343036e-01 2.9938540e-01\n",
      " 4.1835183e-01 3.6845276e-01 3.5065436e-01 3.7338388e-01 3.3021790e-01\n",
      " 3.2282478e-01 9.6532702e-04 1.0000765e-03 2.7811527e-04 1.0135770e-03\n",
      " 2.4839044e-03 4.8312545e-04 1.6972423e-04 1.0970533e-03 4.0960312e-04\n",
      " 3.3369660e-04 1.3929605e-03 1.5745163e-03 9.3036890e-04 2.0831227e-03\n",
      " 7.3951483e-04 6.6557527e-04 1.4723837e-03 2.2935867e-03 1.6651154e-03\n",
      " 1.2049675e-03 2.6568770e-04 3.7986040e-04 1.7740130e-03 1.8349290e-04\n",
      " 1.1137426e-03 2.2204518e-03 1.4153421e-03 2.1309257e-03 1.3524294e-04\n",
      " 5.6442618e-04 4.0948391e-04 1.4343262e-03 1.8468499e-03 2.1621585e-04\n",
      " 6.5189600e-04 8.8742375e-04 7.5086951e-04 4.0626526e-04 2.2001266e-03\n",
      " 1.3249218e-03 1.5438497e-03 8.6593628e-04 1.5512109e-03 1.6694367e-03\n",
      " 3.2529235e-04 1.8904507e-03 1.6371906e-03 1.3591945e-03 1.4886856e-03\n",
      " 1.1163354e-03 8.9073181e-04 9.8863244e-04 9.6359849e-04 3.0732155e-03\n",
      " 4.7519803e-04 8.4933639e-04 1.0165572e-03 1.3538301e-03 1.4509857e-03\n",
      " 9.5206499e-04 5.0321221e-04 5.6913495e-04 2.7275681e-03 7.9146028e-04\n",
      " 3.1289458e-04 1.0868013e-03 7.3465705e-04 1.1648238e-03 7.8430772e-04\n",
      " 2.5177896e-03 1.6210079e-03 1.7604530e-03 1.4510751e-03 1.1975169e-03\n",
      " 1.9299686e-03 1.8211305e-03 7.6112151e-04 3.6653876e-04 9.6774101e-04\n",
      " 5.4386258e-04 7.1635842e-04 1.5347004e-03 1.4750361e-03 1.3914108e-03\n",
      " 1.5344322e-03 6.9034100e-04 1.4011562e-03 5.6597590e-04 8.1667304e-04\n",
      " 4.4506788e-04 1.1575222e-03 1.0671914e-03 1.7714500e-04 9.5105171e-04\n",
      " 1.5323460e-03 8.6835027e-04 7.2208047e-04 9.6642971e-04 1.9139051e-03\n",
      " 3.1524897e-03 1.3540685e-03 4.3329597e-04 7.4958801e-04 9.9935937e-01\n",
      " 1.5988052e-03 1.2334883e-03 5.6266785e-04 6.2140822e-04 1.1569858e-03\n",
      " 5.4970384e-04 1.9207895e-03 2.8515458e-03 6.0796738e-04 9.3430281e-04\n",
      " 7.2032213e-04 6.7988038e-04 7.4431300e-04 9.1513991e-04 4.0718913e-04\n",
      " 1.8823743e-03 8.0665946e-04 1.3997257e-03 1.8906295e-03 7.8800321e-04\n",
      " 1.5494823e-03 2.6112497e-03 8.4289908e-04 7.0884824e-04 1.5296042e-03\n",
      " 8.3836913e-04 4.6569109e-04 8.7457895e-04 1.2165308e-03 3.1411648e-04\n",
      " 1.1983514e-03 1.6735494e-03 9.7087026e-04 7.0518255e-04 1.2975633e-03\n",
      " 1.1299551e-03 2.5118589e-03 5.5873394e-04 6.5135956e-04 1.7528236e-03\n",
      " 8.7699294e-04 1.7391443e-03 7.5125694e-04 2.1150410e-03 1.0814667e-03\n",
      " 8.7913871e-04 1.4926493e-03 4.5505166e-04 9.2136860e-04 2.0427108e-03\n",
      " 7.3447824e-04 1.2246072e-03 5.0801039e-04 1.8530488e-03 8.1059337e-04\n",
      " 4.5347214e-04 3.4281313e-03 1.5658438e-03 9.6839666e-04 6.8101287e-04\n",
      " 1.9925237e-03 3.1955838e-03 9.2074275e-04 1.1023879e-03 2.2597611e-03\n",
      " 6.1652064e-04 2.1537244e-03 6.8679452e-04 1.0823011e-03 6.0302019e-04\n",
      " 1.1918545e-03 2.2871792e-03 9.9420547e-04 2.3251474e-03 2.2020936e-04\n",
      " 9.7909570e-04 2.8150380e-03 2.2304058e-04 2.3227632e-03 2.3748279e-03\n",
      " 3.6364198e-03 1.6506314e-03 2.0797849e-03 3.7434697e-04 5.1811337e-04\n",
      " 2.0845830e-03 1.2871325e-03 9.7563863e-04 1.6594231e-03 8.0579519e-04\n",
      " 9.2667341e-04 1.2933314e-03 3.8793683e-04 1.6714931e-03 1.9348264e-03]\n"
     ]
    }
   ],
   "source": [
    "predictions = model3.predict([x_test])\n",
    "print(np.argmax(predictions[0]))\n",
    "print((predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
